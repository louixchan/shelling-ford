{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we beat the odds?\n",
    "\n",
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\users\\lchan\\documents\\shelling-ford\\venv\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "d:\\users\\lchan\\documents\\shelling-ford\\venv\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.cross_validation import  cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, LeakyReLU, Dropout, Conv1D, MaxPool1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HKRacing\n",
    "This section contains code related to the dataset hkracing (https://www.kaggle.com/gdaley/hkracing/)\n",
    "\n",
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subdomain = 'hkracing/'\n",
    "\n",
    "df_races = pd.read_csv(data_path + data_subdomain + 'races.csv', date_parser=['date'])\n",
    "df_runs = pd.read_csv(data_path + data_subdomain + 'runs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Proprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_races['horse_ratings_lower'] = df_races['horse_ratings'].str.split('-').str[0]\n",
    "df_races['horse_ratings_upper'] = df_races['horse_ratings'].str.split('-').str[1]\n",
    "\n",
    "df_runs['weight_difference'] = df_runs['declared_weight'] - df_runs['actual_weight']\n",
    "df_runs['weight_difference_percentage'] = df_runs['weight_difference'] / df_runs['actual_weight']\n",
    "\n",
    "df_runs['result_encoded'] = 3\n",
    "df_runs.loc[df_runs['result'] == 1, 'result_encoded'] = 1\n",
    "df_runs.loc[df_runs['result'] == 2, 'result_encoded'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_runs.merge(df_races, left_on='race_id', right_on='race_id', how='inner')\n",
    "df_all['prize'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_race_agg = df_all.groupby('race_id').agg({\n",
    "    'horse_id': 'count',\n",
    "    'horse_age': ['mean', 'std'],\n",
    "    'horse_rating': ['mean', 'std'],\n",
    "    'declared_weight': ['mean', 'std'],\n",
    "    'actual_weight': ['mean', 'std'],\n",
    "    'weight_difference': ['mean', 'std'],\n",
    "    'weight_difference_percentage': ['mean', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "df_race_agg.columns = [\n",
    "    'race_id', \n",
    "    'horse_count',\n",
    "    'horse_age_mean',\n",
    "    'horse_age_std',\n",
    "    'horse_rating_mean',\n",
    "    'horse_rating_std',\n",
    "    'declared_weight_mean',\n",
    "    'declared_weight_std',\n",
    "    'actual_weight_mean',\n",
    "    'actual_weight_std',\n",
    "    'weight_difference_mean',\n",
    "    'weight_difference_std',\n",
    "    'weight_difference_percentage_mean',\n",
    "    'weight_difference_percentage_std'\n",
    "]\n",
    "\n",
    "df_all = df_all.merge(df_race_agg, left_on='race_id', right_on='race_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['race_id', 'horse_no', 'horse_id', 'result', 'won', 'lengths_behind',\n",
       "       'horse_age', 'horse_country', 'horse_type', 'horse_rating',\n",
       "       'horse_gear', 'declared_weight', 'actual_weight', 'draw',\n",
       "       'position_sec1', 'position_sec2', 'position_sec3', 'position_sec4',\n",
       "       'position_sec5', 'position_sec6', 'behind_sec1', 'behind_sec2',\n",
       "       'behind_sec3', 'behind_sec4', 'behind_sec5', 'behind_sec6', 'time1',\n",
       "       'time2', 'time3', 'time4', 'time5', 'time6', 'finish_time', 'win_odds',\n",
       "       'place_odds', 'trainer_id', 'jockey_id', 'weight_difference',\n",
       "       'weight_difference_percentage', 'result_encoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_runs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_id</th>\n",
       "      <th>jockey_id</th>\n",
       "      <th>jockey_win_rate_5</th>\n",
       "      <th>jockey_horse_age_5</th>\n",
       "      <th>jockey_horse_rating_5</th>\n",
       "      <th>jockey_weight_difference_percentage_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.689686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.874649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.857398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.987044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.595555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.546435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.586988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.568966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.506038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.547627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.848684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.757004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.843613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.866193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.938638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.871438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.017723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.812294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.754180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.708758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.867649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.866196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.775737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.806457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.768001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.532874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.445374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.469519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.554713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.700796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78735</th>\n",
       "      <td>6292</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>60.4</td>\n",
       "      <td>8.181516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78742</th>\n",
       "      <td>6293</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>58.8</td>\n",
       "      <td>8.127473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78760</th>\n",
       "      <td>6294</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>54.8</td>\n",
       "      <td>7.977551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78770</th>\n",
       "      <td>6295</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>54.8</td>\n",
       "      <td>8.320291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78782</th>\n",
       "      <td>6296</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>46.8</td>\n",
       "      <td>8.309295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78791</th>\n",
       "      <td>6297</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>40.8</td>\n",
       "      <td>8.179513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78802</th>\n",
       "      <td>6298</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>47.4</td>\n",
       "      <td>8.308570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78847</th>\n",
       "      <td>6301</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>51.6</td>\n",
       "      <td>8.582220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78873</th>\n",
       "      <td>6303</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>51.6</td>\n",
       "      <td>8.442814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78879</th>\n",
       "      <td>6304</td>\n",
       "      <td>98</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>55.2</td>\n",
       "      <td>8.519085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78894</th>\n",
       "      <td>6305</td>\n",
       "      <td>98</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>54.2</td>\n",
       "      <td>8.552917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78910</th>\n",
       "      <td>6306</td>\n",
       "      <td>98</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>49.2</td>\n",
       "      <td>8.471124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78916</th>\n",
       "      <td>6307</td>\n",
       "      <td>98</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>59.8</td>\n",
       "      <td>8.421003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78949</th>\n",
       "      <td>6309</td>\n",
       "      <td>98</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>63.8</td>\n",
       "      <td>8.326255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78971</th>\n",
       "      <td>6311</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>68.8</td>\n",
       "      <td>8.289287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78987</th>\n",
       "      <td>6312</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>65.4</td>\n",
       "      <td>8.330588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78996</th>\n",
       "      <td>6313</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>64.2</td>\n",
       "      <td>8.118379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79014</th>\n",
       "      <td>6314</td>\n",
       "      <td>98</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>53.2</td>\n",
       "      <td>8.141382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79024</th>\n",
       "      <td>6315</td>\n",
       "      <td>98</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.4</td>\n",
       "      <td>8.237530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79038</th>\n",
       "      <td>6316</td>\n",
       "      <td>98</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>40.8</td>\n",
       "      <td>8.251729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79045</th>\n",
       "      <td>6317</td>\n",
       "      <td>98</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>48.6</td>\n",
       "      <td>8.357484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79061</th>\n",
       "      <td>6318</td>\n",
       "      <td>98</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>54.2</td>\n",
       "      <td>8.861218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79073</th>\n",
       "      <td>6319</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59.2</td>\n",
       "      <td>8.967998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79096</th>\n",
       "      <td>6321</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>56.2</td>\n",
       "      <td>8.671055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79109</th>\n",
       "      <td>6322</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>58.6</td>\n",
       "      <td>8.472437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79134</th>\n",
       "      <td>6324</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>55.4</td>\n",
       "      <td>8.329344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79152</th>\n",
       "      <td>6325</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>55.8</td>\n",
       "      <td>8.058269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79166</th>\n",
       "      <td>6326</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8.066744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79175</th>\n",
       "      <td>6327</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>8.316278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79190</th>\n",
       "      <td>6328</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.421562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78848 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       race_id  jockey_id  jockey_win_rate_5  jockey_horse_age_5  \\\n",
       "56           4          2                0.4                 3.0   \n",
       "68           5          2                0.4                 3.0   \n",
       "94           7          2                0.2                 3.0   \n",
       "110          8          2                0.2                 3.0   \n",
       "127          9          2                0.0                 3.0   \n",
       "140         10          2                0.0                 3.0   \n",
       "150         11          2                0.0                 3.0   \n",
       "161         12          2                0.0                 3.0   \n",
       "175         13          2                0.2                 3.0   \n",
       "188         14          2                0.2                 3.0   \n",
       "202         15          2                0.4                 3.0   \n",
       "207         16          2                0.4                 3.0   \n",
       "229         17          2                0.4                 3.0   \n",
       "236         18          2                0.2                 3.0   \n",
       "248         19          2                0.2                 3.0   \n",
       "254         20          2                0.0                 3.0   \n",
       "265         21          2                0.2                 3.0   \n",
       "271         22          2                0.2                 3.0   \n",
       "286         23          2                0.4                 3.0   \n",
       "301         24          2                0.4                 3.0   \n",
       "316         25          2                0.4                 3.0   \n",
       "337         27          2                0.2                 3.0   \n",
       "361         29          2                0.2                 3.0   \n",
       "370         30          2                0.0                 3.0   \n",
       "381         31          2                0.0                 3.0   \n",
       "393         32          2                0.0                 3.0   \n",
       "407         33          2                0.0                 3.0   \n",
       "420         34          2                0.0                 3.0   \n",
       "433         35          2                0.2                 3.0   \n",
       "445         36          2                0.2                 3.0   \n",
       "...        ...        ...                ...                 ...   \n",
       "78735     6292         98                0.0                 4.8   \n",
       "78742     6293         98                0.0                 5.0   \n",
       "78760     6294         98                0.0                 4.6   \n",
       "78770     6295         98                0.0                 4.4   \n",
       "78782     6296         98                0.0                 4.4   \n",
       "78791     6297         98                0.0                 4.4   \n",
       "78802     6298         98                0.0                 4.4   \n",
       "78847     6301         98                0.0                 4.0   \n",
       "78873     6303         98                0.0                 4.6   \n",
       "78879     6304         98                0.2                 4.4   \n",
       "78894     6305         98                0.2                 4.8   \n",
       "78910     6306         98                0.2                 4.6   \n",
       "78916     6307         98                0.2                 5.4   \n",
       "78949     6309         98                0.2                 5.4   \n",
       "78971     6311         98                0.0                 5.6   \n",
       "78987     6312         98                0.0                 5.6   \n",
       "78996     6313         98                0.0                 5.2   \n",
       "79014     6314         98                0.2                 5.0   \n",
       "79024     6315         98                0.2                 5.0   \n",
       "79038     6316         98                0.2                 4.8   \n",
       "79045     6317         98                0.2                 4.4   \n",
       "79061     6318         98                0.2                 4.4   \n",
       "79073     6319         98                0.0                 4.0   \n",
       "79096     6321         98                0.0                 3.8   \n",
       "79109     6322         98                0.0                 3.6   \n",
       "79134     6324         98                0.0                 3.8   \n",
       "79152     6325         98                0.0                 3.8   \n",
       "79166     6326         98                0.0                 3.6   \n",
       "79175     6327         98                0.0                 4.2   \n",
       "79190     6328         98                0.0                 4.6   \n",
       "\n",
       "       jockey_horse_rating_5  jockey_weight_difference_percentage_5  \n",
       "56                      60.0                               7.689686  \n",
       "68                      60.0                               7.874649  \n",
       "94                      60.0                               7.857398  \n",
       "110                     60.0                               7.987044  \n",
       "127                     60.0                               7.595555  \n",
       "140                     60.0                               7.546435  \n",
       "150                     60.0                               7.586988  \n",
       "161                     60.0                               7.568966  \n",
       "175                     60.0                               7.506038  \n",
       "188                     60.0                               7.547627  \n",
       "202                     60.0                               7.848684  \n",
       "207                     60.0                               7.757004  \n",
       "229                     60.0                               7.843613  \n",
       "236                     60.0                               7.866193  \n",
       "248                     60.0                               7.938638  \n",
       "254                     60.0                               7.871438  \n",
       "265                     60.0                               8.017723  \n",
       "271                     60.0                               7.812294  \n",
       "286                     60.0                               7.754180  \n",
       "301                     60.0                               7.708758  \n",
       "316                     60.0                               7.867649  \n",
       "337                     60.0                               7.866196  \n",
       "361                     60.0                               7.775737  \n",
       "370                     60.0                               7.806457  \n",
       "381                     60.0                               7.768001  \n",
       "393                     60.0                               7.532874  \n",
       "407                     60.0                               7.445374  \n",
       "420                     60.0                               7.469519  \n",
       "433                     60.0                               7.554713  \n",
       "445                     60.0                               7.700796  \n",
       "...                      ...                                    ...  \n",
       "78735                   60.4                               8.181516  \n",
       "78742                   58.8                               8.127473  \n",
       "78760                   54.8                               7.977551  \n",
       "78770                   54.8                               8.320291  \n",
       "78782                   46.8                               8.309295  \n",
       "78791                   40.8                               8.179513  \n",
       "78802                   47.4                               8.308570  \n",
       "78847                   51.6                               8.582220  \n",
       "78873                   51.6                               8.442814  \n",
       "78879                   55.2                               8.519085  \n",
       "78894                   54.2                               8.552917  \n",
       "78910                   49.2                               8.471124  \n",
       "78916                   59.8                               8.421003  \n",
       "78949                   63.8                               8.326255  \n",
       "78971                   68.8                               8.289287  \n",
       "78987                   65.4                               8.330588  \n",
       "78996                   64.2                               8.118379  \n",
       "79014                   53.2                               8.141382  \n",
       "79024                   50.4                               8.237530  \n",
       "79038                   40.8                               8.251729  \n",
       "79045                   48.6                               8.357484  \n",
       "79061                   54.2                               8.861218  \n",
       "79073                   59.2                               8.967998  \n",
       "79096                   56.2                               8.671055  \n",
       "79109                   58.6                               8.472437  \n",
       "79134                   55.4                               8.329344  \n",
       "79152                   55.8                               8.058269  \n",
       "79166                   51.0                               8.066744  \n",
       "79175                   57.0                               8.316278  \n",
       "79190                   60.0                               8.421562  \n",
       "\n",
       "[78848 rows x 6 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jockeys = list(df_all['jockey_id'].unique())\n",
    "\n",
    "df_jockeys = None\n",
    "\n",
    "for jockey in jockeys:\n",
    "    \n",
    "    df_jockey = df_all[df_all['jockey_id'] == jockey].sort_values(by=['date', 'race_no'])\n",
    "    df_jockey['jockey_win_rate_5'] = np.where(df_jockey['result'] < 3, 1, 0)\n",
    "    df_jockey['jockey_win_rate_5'] = df_jockey['jockey_win_rate_5'].rolling(5).sum() / 5\n",
    "    df_jockey['jockey_horse_age_5'] = df_jockey['horse_age'].rolling(5).mean()\n",
    "    df_jockey['jockey_horse_rating_5'] = df_jockey['horse_rating'].rolling(5).mean()\n",
    "    df_jockey['jockey_weight_difference_percentage_5'] = df_jockey['weight_difference_percentage'].rolling(5).mean()\n",
    "    df_jockey = df_jockey[\n",
    "        [\n",
    "            'race_id', 'jockey_id', 'jockey_win_rate_5', 'jockey_horse_age_5', 'jockey_horse_rating_5', 'jockey_weight_difference_percentage_5'\n",
    "        ]\n",
    "    ]\n",
    "    df_jockey.dropna(inplace=True)\n",
    "    \n",
    "    if df_jockeys is None:\n",
    "        \n",
    "        df_jockeys = df_jockey\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        df_jockeys = df_jockeys.append(df_jockey)\n",
    "    \n",
    "    \n",
    "df_jockeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_id</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>horse_win_rate_5</th>\n",
       "      <th>horse_race_count</th>\n",
       "      <th>horse_horse_rating_5</th>\n",
       "      <th>horse_weight_difference_percentage_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>199</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.791262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>236</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.029842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>258</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.4</td>\n",
       "      <td>7</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.246229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>286</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.4</td>\n",
       "      <td>8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.444004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>312</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.2</td>\n",
       "      <td>9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.611868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4261</th>\n",
       "      <td>339</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.769979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4877</th>\n",
       "      <td>390</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.733159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5618</th>\n",
       "      <td>452</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.515268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6474</th>\n",
       "      <td>520</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.311385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>565</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.2</td>\n",
       "      <td>14</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.131214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7683</th>\n",
       "      <td>617</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.196314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7890</th>\n",
       "      <td>633</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.4</td>\n",
       "      <td>16</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.238112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8356</th>\n",
       "      <td>670</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.4</td>\n",
       "      <td>17</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.444037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8583</th>\n",
       "      <td>688</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.4</td>\n",
       "      <td>18</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.658070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9700</th>\n",
       "      <td>775</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.2</td>\n",
       "      <td>19</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.864986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9932</th>\n",
       "      <td>794</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.797974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10456</th>\n",
       "      <td>836</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.887855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11203</th>\n",
       "      <td>894</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.018993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13918</th>\n",
       "      <td>1109</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.832511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14737</th>\n",
       "      <td>1173</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.645558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15293</th>\n",
       "      <td>1217</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.593552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15966</th>\n",
       "      <td>1272</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.512366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18052</th>\n",
       "      <td>1435</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.396200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18728</th>\n",
       "      <td>1492</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.589502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19168</th>\n",
       "      <td>1530</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.808312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20419</th>\n",
       "      <td>1629</td>\n",
       "      <td>3917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.957803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>181</td>\n",
       "      <td>2157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.587599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>256</td>\n",
       "      <td>2157</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.663145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3452</th>\n",
       "      <td>274</td>\n",
       "      <td>2157</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.720131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5619</th>\n",
       "      <td>452</td>\n",
       "      <td>2157</td>\n",
       "      <td>0.4</td>\n",
       "      <td>8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.685655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79018</th>\n",
       "      <td>6315</td>\n",
       "      <td>4029</td>\n",
       "      <td>0.4</td>\n",
       "      <td>7</td>\n",
       "      <td>57.4</td>\n",
       "      <td>8.277353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79343</th>\n",
       "      <td>6341</td>\n",
       "      <td>1301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>80.4</td>\n",
       "      <td>7.779620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77817</th>\n",
       "      <td>6218</td>\n",
       "      <td>3638</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8.518962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78680</th>\n",
       "      <td>6287</td>\n",
       "      <td>3638</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6</td>\n",
       "      <td>66.6</td>\n",
       "      <td>8.605432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78539</th>\n",
       "      <td>6276</td>\n",
       "      <td>2377</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>52.2</td>\n",
       "      <td>7.211364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79273</th>\n",
       "      <td>6335</td>\n",
       "      <td>2377</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6</td>\n",
       "      <td>52.6</td>\n",
       "      <td>7.238135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79280</th>\n",
       "      <td>6336</td>\n",
       "      <td>1260</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>52.4</td>\n",
       "      <td>7.927810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78110</th>\n",
       "      <td>6243</td>\n",
       "      <td>2151</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>53.8</td>\n",
       "      <td>7.618416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78441</th>\n",
       "      <td>6269</td>\n",
       "      <td>2151</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.664506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79128</th>\n",
       "      <td>6324</td>\n",
       "      <td>2151</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7</td>\n",
       "      <td>54.6</td>\n",
       "      <td>7.697648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78521</th>\n",
       "      <td>6274</td>\n",
       "      <td>4160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>68.4</td>\n",
       "      <td>8.067949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78262</th>\n",
       "      <td>6254</td>\n",
       "      <td>1325</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>65.4</td>\n",
       "      <td>8.196488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78763</th>\n",
       "      <td>6295</td>\n",
       "      <td>1325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>64.2</td>\n",
       "      <td>8.017202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78952</th>\n",
       "      <td>6309</td>\n",
       "      <td>2061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>69.0</td>\n",
       "      <td>8.732846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78235</th>\n",
       "      <td>6252</td>\n",
       "      <td>3056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>48.4</td>\n",
       "      <td>8.809378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78623</th>\n",
       "      <td>6283</td>\n",
       "      <td>3056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>46.4</td>\n",
       "      <td>9.060635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79437</th>\n",
       "      <td>6348</td>\n",
       "      <td>3368</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>87.8</td>\n",
       "      <td>8.107533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79123</th>\n",
       "      <td>6323</td>\n",
       "      <td>141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>51.2</td>\n",
       "      <td>6.957790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78904</th>\n",
       "      <td>6306</td>\n",
       "      <td>1536</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>51.2</td>\n",
       "      <td>8.249932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77785</th>\n",
       "      <td>6216</td>\n",
       "      <td>788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>76.6</td>\n",
       "      <td>7.272451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78674</th>\n",
       "      <td>6287</td>\n",
       "      <td>788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>75.0</td>\n",
       "      <td>7.352279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78091</th>\n",
       "      <td>6241</td>\n",
       "      <td>4357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>51.8</td>\n",
       "      <td>7.796116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78635</th>\n",
       "      <td>6284</td>\n",
       "      <td>4357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>48.8</td>\n",
       "      <td>7.689342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79327</th>\n",
       "      <td>6339</td>\n",
       "      <td>4378</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>63.4</td>\n",
       "      <td>8.425581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78195</th>\n",
       "      <td>6249</td>\n",
       "      <td>2878</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>63.2</td>\n",
       "      <td>9.944384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78116</th>\n",
       "      <td>6243</td>\n",
       "      <td>3367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>51.0</td>\n",
       "      <td>7.724112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78651</th>\n",
       "      <td>6285</td>\n",
       "      <td>3367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>47.4</td>\n",
       "      <td>7.823938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79091</th>\n",
       "      <td>6321</td>\n",
       "      <td>3367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>44.8</td>\n",
       "      <td>7.757107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79324</th>\n",
       "      <td>6339</td>\n",
       "      <td>2062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>70.4</td>\n",
       "      <td>9.043495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79265</th>\n",
       "      <td>6334</td>\n",
       "      <td>1015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>49.6</td>\n",
       "      <td>7.682201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63536 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       race_id  horse_id  horse_win_rate_5  horse_race_count  \\\n",
       "2497       199      3917               0.4                 5   \n",
       "2961       236      3917               0.4                 6   \n",
       "3246       258      3917               0.4                 7   \n",
       "3603       286      3917               0.4                 8   \n",
       "3922       312      3917               0.2                 9   \n",
       "4261       339      3917               0.0                10   \n",
       "4877       390      3917               0.0                11   \n",
       "5618       452      3917               0.0                12   \n",
       "6474       520      3917               0.0                13   \n",
       "7038       565      3917               0.2                14   \n",
       "7683       617      3917               0.2                15   \n",
       "7890       633      3917               0.4                16   \n",
       "8356       670      3917               0.4                17   \n",
       "8583       688      3917               0.4                18   \n",
       "9700       775      3917               0.2                19   \n",
       "9932       794      3917               0.2                20   \n",
       "10456      836      3917               0.0                21   \n",
       "11203      894      3917               0.0                22   \n",
       "13918     1109      3917               0.0                23   \n",
       "14737     1173      3917               0.0                24   \n",
       "15293     1217      3917               0.0                25   \n",
       "15966     1272      3917               0.0                26   \n",
       "18052     1435      3917               0.0                27   \n",
       "18728     1492      3917               0.0                28   \n",
       "19168     1530      3917               0.0                29   \n",
       "20419     1629      3917               0.0                30   \n",
       "2260       181      2157               0.0                 5   \n",
       "3211       256      2157               0.2                 6   \n",
       "3452       274      2157               0.2                 7   \n",
       "5619       452      2157               0.4                 8   \n",
       "...        ...       ...               ...               ...   \n",
       "79018     6315      4029               0.4                 7   \n",
       "79343     6341      1301               0.0                 5   \n",
       "77817     6218      3638               0.2                 5   \n",
       "78680     6287      3638               0.2                 6   \n",
       "78539     6276      2377               0.2                 5   \n",
       "79273     6335      2377               0.4                 6   \n",
       "79280     6336      1260               0.2                 5   \n",
       "78110     6243      2151               0.4                 5   \n",
       "78441     6269      2151               0.6                 6   \n",
       "79128     6324      2151               0.8                 7   \n",
       "78521     6274      4160               0.0                 5   \n",
       "78262     6254      1325               0.2                 5   \n",
       "78763     6295      1325               0.0                 6   \n",
       "78952     6309      2061               0.0                 5   \n",
       "78235     6252      3056               0.0                 5   \n",
       "78623     6283      3056               0.0                 6   \n",
       "79437     6348      3368               0.8                 5   \n",
       "79123     6323       141               0.0                 5   \n",
       "78904     6306      1536               0.2                 5   \n",
       "77785     6216       788               0.0                 5   \n",
       "78674     6287       788               0.0                 6   \n",
       "78091     6241      4357               0.0                 5   \n",
       "78635     6284      4357               0.0                 6   \n",
       "79327     6339      4378               0.2                 5   \n",
       "78195     6249      2878               0.2                 5   \n",
       "78116     6243      3367               0.0                 5   \n",
       "78651     6285      3367               0.0                 6   \n",
       "79091     6321      3367               0.0                 7   \n",
       "79324     6339      2062               0.0                 5   \n",
       "79265     6334      1015               0.0                 5   \n",
       "\n",
       "       horse_horse_rating_5  horse_weight_difference_percentage_5  \n",
       "2497                   60.0                              6.791262  \n",
       "2961                   60.0                              7.029842  \n",
       "3246                   60.0                              7.246229  \n",
       "3603                   60.0                              7.444004  \n",
       "3922                   60.0                              7.611868  \n",
       "4261                   60.0                              7.769979  \n",
       "4877                   60.0                              7.733159  \n",
       "5618                   60.0                              7.515268  \n",
       "6474                   60.0                              7.311385  \n",
       "7038                   60.0                              7.131214  \n",
       "7683                   60.0                              7.196314  \n",
       "7890                   60.0                              7.238112  \n",
       "8356                   60.0                              7.444037  \n",
       "8583                   60.0                              7.658070  \n",
       "9700                   60.0                              7.864986  \n",
       "9932                   60.0                              7.797974  \n",
       "10456                  60.0                              7.887855  \n",
       "11203                  60.0                              8.018993  \n",
       "13918                  60.0                              7.832511  \n",
       "14737                  60.0                              7.645558  \n",
       "15293                  60.0                              7.593552  \n",
       "15966                  60.0                              7.512366  \n",
       "18052                  60.0                              7.396200  \n",
       "18728                  60.0                              7.589502  \n",
       "19168                  60.0                              7.808312  \n",
       "20419                  60.0                              7.957803  \n",
       "2260                   60.0                              6.587599  \n",
       "3211                   60.0                              6.663145  \n",
       "3452                   60.0                              6.720131  \n",
       "5619                   60.0                              6.685655  \n",
       "...                     ...                                   ...  \n",
       "79018                  57.4                              8.277353  \n",
       "79343                  80.4                              7.779620  \n",
       "77817                  67.0                              8.518962  \n",
       "78680                  66.6                              8.605432  \n",
       "78539                  52.2                              7.211364  \n",
       "79273                  52.6                              7.238135  \n",
       "79280                  52.4                              7.927810  \n",
       "78110                  53.8                              7.618416  \n",
       "78441                  54.0                              7.664506  \n",
       "79128                  54.6                              7.697648  \n",
       "78521                  68.4                              8.067949  \n",
       "78262                  65.4                              8.196488  \n",
       "78763                  64.2                              8.017202  \n",
       "78952                  69.0                              8.732846  \n",
       "78235                  48.4                              8.809378  \n",
       "78623                  46.4                              9.060635  \n",
       "79437                  87.8                              8.107533  \n",
       "79123                  51.2                              6.957790  \n",
       "78904                  51.2                              8.249932  \n",
       "77785                  76.6                              7.272451  \n",
       "78674                  75.0                              7.352279  \n",
       "78091                  51.8                              7.796116  \n",
       "78635                  48.8                              7.689342  \n",
       "79327                  63.4                              8.425581  \n",
       "78195                  63.2                              9.944384  \n",
       "78116                  51.0                              7.724112  \n",
       "78651                  47.4                              7.823938  \n",
       "79091                  44.8                              7.757107  \n",
       "79324                  70.4                              9.043495  \n",
       "79265                  49.6                              7.682201  \n",
       "\n",
       "[63536 rows x 6 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horses = list(df_all['horse_id'].unique())\n",
    "\n",
    "df_horses = None\n",
    "\n",
    "for horse in horses:\n",
    "    \n",
    "    df_horse = df_all[df_all['horse_id'] == horse].sort_values(by=['date', 'race_no'])\n",
    "    df_horse['horse_win_rate_5'] = np.where(df_horse['result'] < 3, 1, 0)\n",
    "    df_horse['horse_win_rate_5'] = df_horse['horse_win_rate_5'].rolling(5).sum() / 5\n",
    "    df_horse['horse_race_count'] = (df_horse['horse_id'] == horse).cumsum()\n",
    "    df_horse['horse_horse_rating_5'] = df_horse['horse_rating'].rolling(5).mean()\n",
    "    df_horse['horse_weight_difference_percentage_5'] = df_horse['weight_difference_percentage'].rolling(5).mean()\n",
    "    df_horse = df_horse[\n",
    "        [\n",
    "            'race_id', 'horse_id', 'horse_win_rate_5', 'horse_race_count', 'horse_horse_rating_5', 'horse_weight_difference_percentage_5'\n",
    "        ]\n",
    "    ]\n",
    "    df_horse.dropna(inplace=True)\n",
    "    \n",
    "    if df_horses is None:\n",
    "        \n",
    "        df_horses = df_horse\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        df_horses = df_horses.append(df_horse)\n",
    "    \n",
    "    \n",
    "df_horses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_id</th>\n",
       "      <th>trainer_id</th>\n",
       "      <th>trainer_win_rate_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>4</td>\n",
       "      <td>118</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>5</td>\n",
       "      <td>118</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>7</td>\n",
       "      <td>118</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>8</td>\n",
       "      <td>118</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>9</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>12</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>14</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>15</td>\n",
       "      <td>118</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>16</td>\n",
       "      <td>118</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>17</td>\n",
       "      <td>118</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>18</td>\n",
       "      <td>118</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>20</td>\n",
       "      <td>118</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>23</td>\n",
       "      <td>118</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>24</td>\n",
       "      <td>118</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>25</td>\n",
       "      <td>118</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>26</td>\n",
       "      <td>118</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>33</td>\n",
       "      <td>118</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>36</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>42</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>43</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>43</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>44</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>44</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>45</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>47</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>48</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>48</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>52</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>53</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78905</th>\n",
       "      <td>6306</td>\n",
       "      <td>111</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78931</th>\n",
       "      <td>6308</td>\n",
       "      <td>111</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78968</th>\n",
       "      <td>6311</td>\n",
       "      <td>111</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78989</th>\n",
       "      <td>6312</td>\n",
       "      <td>111</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79014</th>\n",
       "      <td>6314</td>\n",
       "      <td>111</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79023</th>\n",
       "      <td>6315</td>\n",
       "      <td>111</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79034</th>\n",
       "      <td>6316</td>\n",
       "      <td>111</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79048</th>\n",
       "      <td>6317</td>\n",
       "      <td>111</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79078</th>\n",
       "      <td>6320</td>\n",
       "      <td>111</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79112</th>\n",
       "      <td>6322</td>\n",
       "      <td>111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79115</th>\n",
       "      <td>6323</td>\n",
       "      <td>111</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79137</th>\n",
       "      <td>6324</td>\n",
       "      <td>111</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79148</th>\n",
       "      <td>6325</td>\n",
       "      <td>111</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79161</th>\n",
       "      <td>6326</td>\n",
       "      <td>111</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79174</th>\n",
       "      <td>6327</td>\n",
       "      <td>111</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79194</th>\n",
       "      <td>6328</td>\n",
       "      <td>111</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79206</th>\n",
       "      <td>6329</td>\n",
       "      <td>111</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79221</th>\n",
       "      <td>6331</td>\n",
       "      <td>111</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79237</th>\n",
       "      <td>6332</td>\n",
       "      <td>111</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79246</th>\n",
       "      <td>6333</td>\n",
       "      <td>111</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79248</th>\n",
       "      <td>6333</td>\n",
       "      <td>111</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79258</th>\n",
       "      <td>6334</td>\n",
       "      <td>111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79271</th>\n",
       "      <td>6335</td>\n",
       "      <td>111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79283</th>\n",
       "      <td>6336</td>\n",
       "      <td>111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79320</th>\n",
       "      <td>6339</td>\n",
       "      <td>111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79341</th>\n",
       "      <td>6340</td>\n",
       "      <td>111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79345</th>\n",
       "      <td>6341</td>\n",
       "      <td>111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79390</th>\n",
       "      <td>6344</td>\n",
       "      <td>111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79421</th>\n",
       "      <td>6347</td>\n",
       "      <td>111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79444</th>\n",
       "      <td>6348</td>\n",
       "      <td>111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79059 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       race_id  trainer_id  trainer_win_rate_5\n",
       "56           4         118                 0.4\n",
       "68           5         118                 0.4\n",
       "99           7         118                 0.2\n",
       "110          8         118                 0.2\n",
       "122          9         118                 0.0\n",
       "161         12         118                 0.0\n",
       "176         13         118                 0.0\n",
       "188         14         118                 0.0\n",
       "202         15         118                 0.2\n",
       "207         16         118                 0.2\n",
       "229         17         118                 0.2\n",
       "231         18         118                 0.2\n",
       "254         20         118                 0.2\n",
       "286         23         118                 0.2\n",
       "306         24         118                 0.2\n",
       "316         25         118                 0.2\n",
       "322         26         118                 0.2\n",
       "407         33         118                 0.2\n",
       "439         36         118                 0.0\n",
       "522         42         118                 0.0\n",
       "535         43         118                 0.0\n",
       "536         43         118                 0.0\n",
       "540         44         118                 0.0\n",
       "553         44         118                 0.0\n",
       "555         45         118                 0.0\n",
       "579         47         118                 0.0\n",
       "589         48         118                 0.0\n",
       "590         48         118                 0.0\n",
       "643         52         118                 0.0\n",
       "654         53         118                 0.0\n",
       "...        ...         ...                 ...\n",
       "78905     6306         111                 0.4\n",
       "78931     6308         111                 0.4\n",
       "78968     6311         111                 0.2\n",
       "78989     6312         111                 0.2\n",
       "79014     6314         111                 0.2\n",
       "79023     6315         111                 0.2\n",
       "79034     6316         111                 0.2\n",
       "79048     6317         111                 0.2\n",
       "79078     6320         111                 0.2\n",
       "79112     6322         111                 0.0\n",
       "79115     6323         111                 0.2\n",
       "79137     6324         111                 0.4\n",
       "79148     6325         111                 0.6\n",
       "79161     6326         111                 0.6\n",
       "79174     6327         111                 0.6\n",
       "79194     6328         111                 0.4\n",
       "79206     6329         111                 0.4\n",
       "79221     6331         111                 0.2\n",
       "79237     6332         111                 0.2\n",
       "79246     6333         111                 0.2\n",
       "79248     6333         111                 0.2\n",
       "79258     6334         111                 0.0\n",
       "79271     6335         111                 0.0\n",
       "79283     6336         111                 0.0\n",
       "79320     6339         111                 0.0\n",
       "79341     6340         111                 0.0\n",
       "79345     6341         111                 0.0\n",
       "79390     6344         111                 0.0\n",
       "79421     6347         111                 0.0\n",
       "79444     6348         111                 0.0\n",
       "\n",
       "[79059 rows x 3 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainers = list(df_all['trainer_id'].unique())\n",
    "\n",
    "df_trainers = None\n",
    "\n",
    "for trainer in trainers:\n",
    "    \n",
    "    df_trainer = df_all[df_all['trainer_id'] == trainer].sort_values(by=['date', 'race_no'])\n",
    "    df_trainer['trainer_win_rate_5'] = np.where(df_trainer['result'] < 3, 1, 0)\n",
    "    df_trainer['trainer_win_rate_5'] = df_trainer['trainer_win_rate_5'].rolling(5).sum() / 5\n",
    "    df_trainer = df_trainer[\n",
    "        [\n",
    "            'race_id', 'trainer_id', 'trainer_win_rate_5'\n",
    "        ]\n",
    "    ]\n",
    "    df_trainer.dropna(inplace=True)\n",
    "    \n",
    "    if df_trainers is None:\n",
    "        \n",
    "        df_trainers = df_trainer\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        df_trainers = df_trainers.append(df_trainer)\n",
    "    \n",
    "    \n",
    "df_trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.merge(df_jockeys, left_on=['race_id', 'jockey_id'], right_on=['race_id', 'jockey_id'], how='inner')\n",
    "df_all = df_all.merge(df_horses, left_on=['race_id', 'horse_id'], right_on=['race_id', 'horse_id'], how='inner')\n",
    "df_all = df_all.merge(df_trainers, left_on=['race_id', 'trainer_id'], right_on=['race_id', 'trainer_id'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_id</th>\n",
       "      <th>horse_no</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>result</th>\n",
       "      <th>won</th>\n",
       "      <th>lengths_behind</th>\n",
       "      <th>horse_age</th>\n",
       "      <th>horse_country</th>\n",
       "      <th>horse_type</th>\n",
       "      <th>horse_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>weight_difference_percentage_std</th>\n",
       "      <th>jockey_win_rate_5</th>\n",
       "      <th>jockey_horse_age_5</th>\n",
       "      <th>jockey_horse_rating_5</th>\n",
       "      <th>jockey_weight_difference_percentage_5</th>\n",
       "      <th>horse_win_rate_5</th>\n",
       "      <th>horse_race_count</th>\n",
       "      <th>horse_horse_rating_5</th>\n",
       "      <th>horse_weight_difference_percentage_5</th>\n",
       "      <th>trainer_win_rate_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>5</td>\n",
       "      <td>876</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3</td>\n",
       "      <td>NZ</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.563337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.069224</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116</td>\n",
       "      <td>11</td>\n",
       "      <td>550</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3</td>\n",
       "      <td>USA</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.547707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.440906</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>1853</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3</td>\n",
       "      <td>SAF</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.706870</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.578946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.735458</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119</td>\n",
       "      <td>9</td>\n",
       "      <td>876</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3</td>\n",
       "      <td>NZ</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.706870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.840423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.082676</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119</td>\n",
       "      <td>9</td>\n",
       "      <td>876</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3</td>\n",
       "      <td>NZ</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.706870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.840423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.082676</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   race_id  horse_no  horse_id  result  won  lengths_behind  horse_age  \\\n",
       "0       94         5       876       9  0.0            3.75          3   \n",
       "1      116        11       550       9  0.0            5.00          3   \n",
       "2      119         5      1853       3  0.0            3.00          3   \n",
       "3      119         9       876      13  0.0           13.00          3   \n",
       "4      119         9       876      13  0.0           13.00          3   \n",
       "\n",
       "  horse_country horse_type  horse_rating         ...          \\\n",
       "0            NZ    Gelding            60         ...           \n",
       "1           USA    Gelding            60         ...           \n",
       "2           SAF    Gelding            60         ...           \n",
       "3            NZ    Gelding            60         ...           \n",
       "4            NZ    Gelding            60         ...           \n",
       "\n",
       "  weight_difference_percentage_std  jockey_win_rate_5  jockey_horse_age_5  \\\n",
       "0                         0.552276                0.0                 3.0   \n",
       "1                         0.761101                0.0                 3.0   \n",
       "2                         0.706870                0.4                 3.0   \n",
       "3                         0.706870                0.0                 3.0   \n",
       "4                         0.706870                0.0                 3.0   \n",
       "\n",
       "   jockey_horse_rating_5  jockey_weight_difference_percentage_5  \\\n",
       "0                   60.0                               7.563337   \n",
       "1                   60.0                               8.547707   \n",
       "2                   60.0                               7.578946   \n",
       "3                   60.0                               7.840423   \n",
       "4                   60.0                               7.840423   \n",
       "\n",
       "   horse_win_rate_5  horse_race_count  horse_horse_rating_5  \\\n",
       "0               0.0                 5                  60.0   \n",
       "1               0.0                 5                  60.0   \n",
       "2               0.0                 5                  60.0   \n",
       "3               0.0                 6                  60.0   \n",
       "4               0.0                 6                  60.0   \n",
       "\n",
       "   horse_weight_difference_percentage_5  trainer_win_rate_5  \n",
       "0                              8.069224                 0.0  \n",
       "1                              8.440906                 0.0  \n",
       "2                              7.735458                 0.0  \n",
       "3                              8.082676                 0.4  \n",
       "4                              8.082676                 0.4  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in df_all.horse_type.unique():\n",
    "    \n",
    "    df_all['horse_type_' + t.lower()] = np.where(df_all['horse_type'] == t, 1, 0)\n",
    "    \n",
    "for t in df_all.horse_country.unique():\n",
    "    \n",
    "    df_all['horse_country_' + t.lower()] = np.where(df_all['horse_country'] == t, 1, 0)\n",
    "    \n",
    "for t in df_all.venue.unique():\n",
    "    \n",
    "    df_all['venue_' + t.lower()] = np.where(df_all['venue'] == t, 1, 0)\n",
    "    \n",
    "for t in df_all.surface.unique():\n",
    "    \n",
    "    df_all['surface_' + str(t).lower()] = np.where(df_all['surface'] == t, 1, 0)\n",
    "    \n",
    "for t in df_all.horse_gear.unique():\n",
    "    \n",
    "    df_all['horse_gear_' + t.lower()] = np.where(df_all['horse_gear'] == t, 1, 0)\n",
    "    \n",
    "df_all['going_good'] = np.where(df_all['going'].str.contains('GOOD'), 1, 0)\n",
    "df_all['going_firm'] = np.where(df_all['going'].str.contains('FIRM'), 1, 0)\n",
    "df_all['going_fast'] = np.where(df_all['going'].str.contains('FAST'), 1, 0)\n",
    "df_all['going_yielding'] = np.where(df_all['going'].str.contains('YIELDING'), 1, 0)\n",
    "df_all['going_soft'] = np.where(df_all['going'].str.contains('SOFT'), 1, 0)\n",
    "df_all['going_slow'] = np.where(df_all['going'].str.contains('SLOW'), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['race_id', 'horse_no', 'horse_id', 'result', 'won', 'lengths_behind',\n",
       "       'horse_age', 'horse_country', 'horse_type', 'horse_rating',\n",
       "       ...\n",
       "       'horse_gear_cp-/p2', 'horse_gear_tt/xb/v2', 'horse_gear_tt1/xb-/h/b1',\n",
       "       'horse_gear_v-/xb1/b2/h2', 'going_good', 'going_firm', 'going_fast',\n",
       "       'going_yielding', 'going_soft', 'going_slow'],\n",
       "      dtype='object', length=874)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KERAS MODEL 1\n",
    "This model attempts to predict the finishing position (top 2 are the ones of interest).\n",
    "However, the best that I can get so far is at 16% which is only slightly better than guessing the winning pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['draw', 'win_odds', 'weight_difference', 'weight_difference_percentage',\n",
       "       'result_encoded', 'surface', 'distance', 'prize', 'race_class',\n",
       "       'horse_count',\n",
       "       ...\n",
       "       'horse_gear_cp-/p2', 'horse_gear_tt/xb/v2', 'horse_gear_tt1/xb-/h/b1',\n",
       "       'horse_gear_v-/xb1/b2/h2', 'going_good', 'going_firm', 'going_fast',\n",
       "       'going_yielding', 'going_soft', 'going_slow'],\n",
       "      dtype='object', length=805)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keras = df_all.drop(\n",
    "    [\n",
    "        'race_id', 'horse_no', 'horse_id', 'won', 'jockey_id', 'trainer_id',\n",
    "        'horse_age', 'horse_country', 'horse_type', 'horse_rating', 'horse_gear', \n",
    "        'declared_weight', 'actual_weight', 'position_sec1', 'position_sec2',\n",
    "        'position_sec3', 'position_sec4', 'position_sec5', 'position_sec6',\n",
    "        'behind_sec1', 'behind_sec2', 'behind_sec3', 'behind_sec4', 'behind_sec5', \n",
    "        'behind_sec6', 'time1_x', 'time2_x', 'time3_x', 'time4_x', 'time5_x', \n",
    "        'time6_x', 'finish_time', 'venue', 'race_no', 'result', 'date', 'config', \n",
    "        'going', 'sec_time1', 'sec_time2', 'sec_time3', 'sec_time4', 'sec_time5', \n",
    "        'sec_time6', 'sec_time7', 'time1_y', 'time2_y', 'time3_y', 'time4_y', \n",
    "        'time5_y', 'time6_y', 'time7', 'place_combination1', 'place_combination2',\n",
    "        'place_combination3', 'place_combination4', 'place_dividend1',\n",
    "        'place_dividend2', 'place_dividend3', 'place_dividend4',\n",
    "        'win_combination1', 'win_dividend1', 'win_combination2',\n",
    "        'win_dividend2', 'lengths_behind', 'place_odds', 'horse_ratings_lower', \n",
    "        'horse_ratings_upper', 'horse_ratings'\n",
    "    ], \n",
    "    axis=1)\n",
    "df_keras.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keras.columns[list(df_keras.isnull().any())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 128)               103040    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 169,089\n",
      "Trainable params: 169,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, \n",
    "                  input_shape=(len(df_keras.columns) - 1,), \n",
    "                  activation=None))\n",
    "# model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Dense(256, activation=None))\n",
    "# model.add(LeakyReLU(alpha=0.3))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "# model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(1, activation=None))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[metrics.binary_accuracy])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_keras['result_encoded']\n",
    "X = df_keras.drop('result_encoded', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52252 samples, validate on 13064 samples\n",
      "Epoch 1/10\n",
      "52252/52252 [==============================] - 9s 172us/step - loss: -23.9499 - binary_accuracy: 0.1568 - val_loss: -26.4885 - val_binary_accuracy: 0.1692\n",
      "Epoch 2/10\n",
      "52252/52252 [==============================] - 8s 150us/step - loss: -26.6723 - binary_accuracy: 0.1632 - val_loss: -26.4885 - val_binary_accuracy: 0.1692\n",
      "Epoch 3/10\n",
      "52252/52252 [==============================] - 8s 153us/step - loss: -26.6757 - binary_accuracy: 0.1632 - val_loss: -26.4885 - val_binary_accuracy: 0.1692\n",
      "Epoch 4/10\n",
      "52252/52252 [==============================] - 8s 150us/step - loss: -26.6769 - binary_accuracy: 0.1632 - val_loss: -26.4885 - val_binary_accuracy: 0.1692\n",
      "Epoch 5/10\n",
      "52252/52252 [==============================] - 8s 155us/step - loss: -26.6711 - binary_accuracy: 0.1632 - val_loss: -26.4885 - val_binary_accuracy: 0.1692\n",
      "Epoch 6/10\n",
      "52252/52252 [==============================] - 9s 164us/step - loss: -26.6764 - binary_accuracy: 0.1632 - val_loss: -26.4885 - val_binary_accuracy: 0.1692\n",
      "Epoch 7/10\n",
      "52252/52252 [==============================] - 9s 164us/step - loss: -26.6787 - binary_accuracy: 0.1632 - val_loss: -26.4885 - val_binary_accuracy: 0.1692\n",
      "Epoch 8/10\n",
      "52252/52252 [==============================] - 8s 154us/step - loss: -26.6769 - binary_accuracy: 0.1632 - val_loss: -26.4885 - val_binary_accuracy: 0.1692\n",
      "Epoch 9/10\n",
      "52252/52252 [==============================] - 8s 157us/step - loss: -26.6769 - binary_accuracy: 0.1632 - val_loss: -26.4885 - val_binary_accuracy: 0.1692\n",
      "Epoch 10/10\n",
      "52252/52252 [==============================] - 9s 164us/step - loss: -26.6754 - binary_accuracy: 0.1632 - val_loss: -26.4885 - val_binary_accuracy: 0.1692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x231bbbbf3c8>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model_name = \"keiba_model_g2.h5\"\n",
    "checkpointer = ModelCheckpoint(filepath='../results/'+save_model_name, verbose=0)\n",
    "\n",
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          batch_size=64, \n",
    "          epochs=10, \n",
    "          verbose=1, \n",
    "          callbacks=[checkpointer],\n",
    "          validation_split=0.2,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KERAS MODEL 2\n",
    "This model attempts to predict the finishing position (top 3 are the ones of interest).\n",
    "However, the best that I can get so far is < 30% which is only slightly better than guessing the winning trio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keras_2 = df_all.drop(\n",
    "    [\n",
    "        'race_id', 'horse_no', 'horse_id', 'won', 'jockey_id', 'trainer_id',\n",
    "        'horse_age', 'horse_country', 'horse_type', 'horse_rating', 'horse_gear', \n",
    "        'declared_weight', 'actual_weight', 'position_sec1', 'position_sec2',\n",
    "        'position_sec3', 'position_sec4', 'position_sec5', 'position_sec6',\n",
    "        'behind_sec1', 'behind_sec2', 'behind_sec3', 'behind_sec4', 'behind_sec5', \n",
    "        'behind_sec6', 'time1_x', 'time2_x', 'time3_x', 'time4_x', 'time5_x', \n",
    "        'time6_x', 'finish_time', 'venue', 'race_no', 'date', 'config', \n",
    "        'going', 'sec_time1', 'sec_time2', 'sec_time3', 'sec_time4', 'sec_time5', \n",
    "        'sec_time6', 'sec_time7', 'time1_y', 'time2_y', 'time3_y', 'time4_y', \n",
    "        'time5_y', 'time6_y', 'time7', 'place_combination1', 'place_combination2',\n",
    "        'place_combination3', 'place_combination4', 'place_dividend1',\n",
    "        'place_dividend2', 'place_dividend3', 'place_dividend4',\n",
    "        'win_combination1', 'win_dividend1', 'win_combination2',\n",
    "        'win_dividend2', 'lengths_behind', 'place_odds', 'horse_ratings_lower', \n",
    "        'horse_ratings_upper', 'horse_ratings'\n",
    "    ], \n",
    "    axis=1)\n",
    "\n",
    "df_keras_2['result_encoded'] = 4\n",
    "df_keras_2.loc[df_runs['result'] < 4, 'result_encoded'] = 1\n",
    "# df_keras_2.loc[df_runs['result'] == 2, 'result_encoded'] = 1\n",
    "\n",
    "df_keras_2.drop('result', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 128)               103040    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 169,089\n",
      "Trainable params: 169,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, \n",
    "                  input_shape=(len(df_keras_2.columns) - 1,), \n",
    "                  activation=None))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Dense(256, activation=None))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(1, activation=None))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[metrics.binary_accuracy])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_keras_2['result_encoded']\n",
    "X = df_keras_2.drop('result_encoded', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52252 samples, validate on 13064 samples\n",
      "Epoch 1/10\n",
      "52252/52252 [==============================] - 11s 211us/step - loss: -2.9451 - binary_accuracy: 0.1509 - val_loss: -36.4708 - val_binary_accuracy: 0.2374\n",
      "Epoch 2/10\n",
      "52252/52252 [==============================] - 9s 172us/step - loss: -35.1608 - binary_accuracy: 0.2379 - val_loss: -36.4708 - val_binary_accuracy: 0.2374\n",
      "Epoch 3/10\n",
      "52252/52252 [==============================] - 10s 189us/step - loss: -35.7850 - binary_accuracy: 0.2395 - val_loss: -36.4708 - val_binary_accuracy: 0.2374\n",
      "Epoch 4/10\n",
      "52252/52252 [==============================] - 11s 213us/step - loss: -36.1743 - binary_accuracy: 0.2407 - val_loss: -36.4708 - val_binary_accuracy: 0.2374\n",
      "Epoch 5/10\n",
      "52252/52252 [==============================] - 10s 200us/step - loss: -36.1763 - binary_accuracy: 0.2407 - val_loss: -36.4708 - val_binary_accuracy: 0.2374\n",
      "Epoch 6/10\n",
      "52252/52252 [==============================] - 9s 179us/step - loss: -36.2415 - binary_accuracy: 0.2408 - val_loss: -36.4708 - val_binary_accuracy: 0.2374\n",
      "Epoch 7/10\n",
      "52252/52252 [==============================] - 9s 178us/step - loss: -36.2600 - binary_accuracy: 0.2408 - val_loss: -36.4708 - val_binary_accuracy: 0.2374\n",
      "Epoch 8/10\n",
      "52252/52252 [==============================] - 9s 175us/step - loss: -36.2838 - binary_accuracy: 0.2410 - val_loss: -36.4708 - val_binary_accuracy: 0.2374\n",
      "Epoch 9/10\n",
      "52252/52252 [==============================] - 9s 181us/step - loss: -36.2849 - binary_accuracy: 0.2410 - val_loss: -36.4708 - val_binary_accuracy: 0.2374\n",
      "Epoch 10/10\n",
      "52252/52252 [==============================] - 9s 180us/step - loss: -36.2904 - binary_accuracy: 0.2410 - val_loss: -36.4708 - val_binary_accuracy: 0.2374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23182cb8240>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model_name = \"keiba_model_g2.h5\"\n",
    "checkpointer = ModelCheckpoint(filepath='../results/'+save_model_name, verbose=0)\n",
    "\n",
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          batch_size=64, \n",
    "          epochs=10, \n",
    "          verbose=1, \n",
    "          callbacks=[checkpointer],\n",
    "          validation_split=0.2,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KERAS MODEL 3\n",
    "This model attempts to predict the finishing time.\n",
    "<br>\n",
    "This approach is inspired by https://medium.com/@paulingliam/using-ml-to-predict-horse-race-time-duration-6340776536e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keras_3 = df_all.drop(\n",
    "    [\n",
    "        'horse_no', 'horse_id', 'won', 'jockey_id', 'trainer_id',\n",
    "        'horse_age', 'horse_country', 'horse_type', 'horse_rating', 'horse_gear', \n",
    "        'declared_weight', 'actual_weight', 'position_sec1', 'position_sec2',\n",
    "        'position_sec3', 'position_sec4', 'position_sec5', 'position_sec6',\n",
    "        'behind_sec1', 'behind_sec2', 'behind_sec3', 'behind_sec4', 'behind_sec5', \n",
    "        'behind_sec6', 'time1_x', 'time2_x', 'time3_x', 'time4_x', 'time5_x', \n",
    "        'time6_x', 'venue', 'race_no', 'date', 'config', 'result', 'result_encoded',\n",
    "        'going', 'sec_time1', 'sec_time2', 'sec_time3', 'sec_time4', 'sec_time5', \n",
    "        'sec_time6', 'sec_time7', 'time1_y', 'time2_y', 'time3_y', 'time4_y', \n",
    "        'time5_y', 'time6_y', 'time7', 'place_combination1', 'place_combination2',\n",
    "        'place_combination3', 'place_combination4', 'place_dividend1',\n",
    "        'place_dividend2', 'place_dividend3', 'place_dividend4',\n",
    "        'win_combination1', 'win_dividend1', 'win_combination2',\n",
    "        'win_dividend2', 'lengths_behind', 'place_odds', 'horse_ratings_lower', \n",
    "        'horse_ratings_upper', 'horse_ratings'\n",
    "    ], \n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keras_3.drop(df_keras_3.columns[[x.startswith('horse_gear') for x in df_keras_3.columns]], axis=1, inplace=True)\n",
    "df_keras_3.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65316, 804)\n",
      "(7258, 804)\n"
     ]
    }
   ],
   "source": [
    "Y = df_keras_3['finish_time'].values\n",
    "X = df_keras_3.drop(['finish_time', 'race_id'], axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_76 (Dense)             (None, 128)               103040    \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 169,089\n",
      "Trainable params: 169,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, input_shape=(len(df_keras_3.columns) - 2,), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation=None))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
    "              loss='mse')\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52252 samples, validate on 13064 samples\n",
      "Epoch 1/10\n",
      "52252/52252 [==============================] - 6s 113us/step - loss: 7921.9628 - val_loss: 7817.6774\n",
      "Epoch 2/10\n",
      "52252/52252 [==============================] - 4s 85us/step - loss: 7866.5099 - val_loss: 7817.6774\n",
      "Epoch 3/10\n",
      "52252/52252 [==============================] - 5s 91us/step - loss: 7851.9955 - val_loss: 7817.6774\n",
      "Epoch 4/10\n",
      "52252/52252 [==============================] - 4s 85us/step - loss: 7835.6014 - val_loss: 7817.6774\n",
      "Epoch 5/10\n",
      "52252/52252 [==============================] - 5s 87us/step - loss: 7829.9770 - val_loss: 7817.6774\n",
      "Epoch 6/10\n",
      "52252/52252 [==============================] - 5s 88us/step - loss: 7828.5510 - val_loss: 7817.6774\n",
      "Epoch 7/10\n",
      "52252/52252 [==============================] - 5s 88us/step - loss: 7825.4812 - val_loss: 7817.6774\n",
      "Epoch 8/10\n",
      "52252/52252 [==============================] - 5s 88us/step - loss: 7823.1469 - val_loss: 7817.6774\n",
      "Epoch 9/10\n",
      "52252/52252 [==============================] - 5s 90us/step - loss: 7821.5763 - val_loss: 7817.6774\n",
      "Epoch 10/10\n",
      "52252/52252 [==============================] - 5s 88us/step - loss: 7820.0451 - val_loss: 7817.6774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x231ab1d3da0>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model_name = \"keiba_model_g2.h5\"\n",
    "checkpointer = ModelCheckpoint(filepath='../results/'+save_model_name, verbose=0)\n",
    "\n",
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          batch_size=64, \n",
    "          epochs=10, \n",
    "          verbose=1, \n",
    "          callbacks=[checkpointer],\n",
    "          validation_split=0.2,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7258, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7258, 1)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "model.predict(X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 97.32, 103.68,  68.87, ...,  99.3 , 100.19,  71.04])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RANDOM FOREST\n",
    "Because the above is not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf_fit = df_keras_3[:int(len(df_keras_3) * 0.8)]\n",
    "df_rf_walk = df_keras_3[int(len(df_keras_3) * 0.8):]\n",
    "\n",
    "Y = df_rf_fit['finish_time'].values\n",
    "X = df_rf_fit.drop(['finish_time', 'race_id'], axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestRegressor(n_estimators=100)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 83.1807, 101.6294, 112.284 , ...,  70.6739, 101.9711,  97.8268])"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.8\n"
     ]
    }
   ],
   "source": [
    "forest_score = round(forest.score(X_test, y_test) * 100, 2)\n",
    "print(forest_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, y_pred, edgecolors=(0, 0, 0))\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=1)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "races = (df_rf_walk.groupby('race_id').agg({'race_id': 'count'}) > 10).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "race = races[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = df_keras_3[df_keras_3['race_id'] == race]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41220    12\n",
       "41221    12\n",
       "41222    12\n",
       "41223    12\n",
       "41224    12\n",
       "41225    12\n",
       "41226    12\n",
       "41227    12\n",
       "41228    12\n",
       "41229    12\n",
       "41230    12\n",
       "Name: horse_count, dtype: int64"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.horse_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_trial = trial['finish_time'].values\n",
    "X_trial = trial.drop(['finish_time', 'race_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>draw</th>\n",
       "      <th>win_odds</th>\n",
       "      <th>weight_difference</th>\n",
       "      <th>weight_difference_percentage</th>\n",
       "      <th>surface</th>\n",
       "      <th>distance</th>\n",
       "      <th>prize</th>\n",
       "      <th>race_class</th>\n",
       "      <th>horse_count</th>\n",
       "      <th>horse_age_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>venue_hv</th>\n",
       "      <th>venue_st</th>\n",
       "      <th>surface_0</th>\n",
       "      <th>surface_1</th>\n",
       "      <th>going_good</th>\n",
       "      <th>going_firm</th>\n",
       "      <th>going_fast</th>\n",
       "      <th>going_yielding</th>\n",
       "      <th>going_soft</th>\n",
       "      <th>going_slow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72562</th>\n",
       "      <td>9</td>\n",
       "      <td>29.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>6.664122</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1750000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4.071429</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72563</th>\n",
       "      <td>10</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>8.369231</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1750000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4.071429</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72565</th>\n",
       "      <td>3</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>8.085271</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1750000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4.071429</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72566</th>\n",
       "      <td>14</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>7.960938</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1750000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4.071429</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72567</th>\n",
       "      <td>7</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>8.055118</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1750000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4.071429</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72568</th>\n",
       "      <td>11</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>8.158730</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1750000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4.071429</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72569</th>\n",
       "      <td>11</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>8.158730</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1750000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4.071429</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72570</th>\n",
       "      <td>8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>935.0</td>\n",
       "      <td>7.480000</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1750000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4.071429</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72571</th>\n",
       "      <td>6</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>8.762295</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1750000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4.071429</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72572</th>\n",
       "      <td>4</td>\n",
       "      <td>99.0</td>\n",
       "      <td>951.0</td>\n",
       "      <td>7.991597</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1750000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4.071429</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72573</th>\n",
       "      <td>1</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>8.566667</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1750000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4.071429</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       draw  win_odds  weight_difference  weight_difference_percentage  \\\n",
       "72562     9      29.0              873.0                      6.664122   \n",
       "72563    10      25.0             1088.0                      8.369231   \n",
       "72565     3      46.0             1043.0                      8.085271   \n",
       "72566    14       1.6             1019.0                      7.960938   \n",
       "72567     7      84.0             1023.0                      8.055118   \n",
       "72568    11      36.0             1028.0                      8.158730   \n",
       "72569    11      36.0             1028.0                      8.158730   \n",
       "72570     8       6.8              935.0                      7.480000   \n",
       "72571     6      99.0             1069.0                      8.762295   \n",
       "72572     4      99.0              951.0                      7.991597   \n",
       "72573     1      99.0             1028.0                      8.566667   \n",
       "\n",
       "       surface  distance      prize  race_class  horse_count  horse_age_mean  \\\n",
       "72562        0      1600  1750000.0           2           14        4.071429   \n",
       "72563        0      1600  1750000.0           2           14        4.071429   \n",
       "72565        0      1600  1750000.0           2           14        4.071429   \n",
       "72566        0      1600  1750000.0           2           14        4.071429   \n",
       "72567        0      1600  1750000.0           2           14        4.071429   \n",
       "72568        0      1600  1750000.0           2           14        4.071429   \n",
       "72569        0      1600  1750000.0           2           14        4.071429   \n",
       "72570        0      1600  1750000.0           2           14        4.071429   \n",
       "72571        0      1600  1750000.0           2           14        4.071429   \n",
       "72572        0      1600  1750000.0           2           14        4.071429   \n",
       "72573        0      1600  1750000.0           2           14        4.071429   \n",
       "\n",
       "          ...      venue_hv  venue_st  surface_0  surface_1  going_good  \\\n",
       "72562     ...             0         1          1          0           1   \n",
       "72563     ...             0         1          1          0           1   \n",
       "72565     ...             0         1          1          0           1   \n",
       "72566     ...             0         1          1          0           1   \n",
       "72567     ...             0         1          1          0           1   \n",
       "72568     ...             0         1          1          0           1   \n",
       "72569     ...             0         1          1          0           1   \n",
       "72570     ...             0         1          1          0           1   \n",
       "72571     ...             0         1          1          0           1   \n",
       "72572     ...             0         1          1          0           1   \n",
       "72573     ...             0         1          1          0           1   \n",
       "\n",
       "       going_firm  going_fast  going_yielding  going_soft  going_slow  \n",
       "72562           0           0               0           0           0  \n",
       "72563           0           0               0           0           0  \n",
       "72565           0           0               0           0           0  \n",
       "72566           0           0               0           0           0  \n",
       "72567           0           0               0           0           0  \n",
       "72568           0           0               0           0           0  \n",
       "72569           0           0               0           0           0  \n",
       "72570           0           0               0           0           0  \n",
       "72571           0           0               0           0           0  \n",
       "72572           0           0               0           0           0  \n",
       "72573           0           0               0           0           0  \n",
       "\n",
       "[11 rows x 64 columns]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest.predict(X_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.1972, -0.0544,  0.0109, -0.25  , -0.163 ,  0.0311,  0.0461,\n",
       "       -0.0385,  0.0176, -0.0983,  0.0658])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred - Y_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(y_pred, columns=['predicted_finishing_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([results, pd.DataFrame(Y_trial, columns=['actual_finishing_time'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_rank</th>\n",
       "      <th>predicted_rank</th>\n",
       "      <th>predicted_finishing_time</th>\n",
       "      <th>actual_finishing_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0454</td>\n",
       "      <td>69.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70.1700</td>\n",
       "      <td>70.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>70.1844</td>\n",
       "      <td>70.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>70.4143</td>\n",
       "      <td>70.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>70.5015</td>\n",
       "      <td>70.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>70.6246</td>\n",
       "      <td>70.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>70.5153</td>\n",
       "      <td>70.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>70.5435</td>\n",
       "      <td>70.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>70.8233</td>\n",
       "      <td>70.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>70.8143</td>\n",
       "      <td>70.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>70.8889</td>\n",
       "      <td>71.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>71.5251</td>\n",
       "      <td>71.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    actual_rank  predicted_rank  predicted_finishing_time  \\\n",
       "0             0               0                   70.0454   \n",
       "1             1               1                   70.1700   \n",
       "2             2               2                   70.1844   \n",
       "3             3               3                   70.4143   \n",
       "4             4               4                   70.5015   \n",
       "5             5               7                   70.6246   \n",
       "6             6               5                   70.5153   \n",
       "7             7               6                   70.5435   \n",
       "8             8               9                   70.8233   \n",
       "9             9               8                   70.8143   \n",
       "10           10              10                   70.8889   \n",
       "11           11              11                   71.5251   \n",
       "\n",
       "    actual_finishing_time  \n",
       "0                   69.84  \n",
       "1                   70.08  \n",
       "2                   70.08  \n",
       "3                   70.28  \n",
       "4                   70.31  \n",
       "5                   70.50  \n",
       "6                   70.51  \n",
       "7                   70.59  \n",
       "8                   70.81  \n",
       "9                   70.96  \n",
       "10                  71.01  \n",
       "11                  71.82  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = results.sort_values(by='predicted_finishing_time').reset_index(drop=True).reset_index()\n",
    "results.columns=['predicted_rank', 'predicted_finishing_time', 'actual_finishing_time']\n",
    "results = results.sort_values(by='actual_finishing_time').reset_index(drop=True).reset_index()\n",
    "results.columns=['actual_rank', 'predicted_rank', 'predicted_finishing_time', 'actual_finishing_time']\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        20.0\n",
       "1        26.0\n",
       "2        11.0\n",
       "3        31.0\n",
       "5        25.0\n",
       "7        17.0\n",
       "8        16.0\n",
       "9        26.0\n",
       "10        8.2\n",
       "11       57.0\n",
       "13       25.0\n",
       "14        9.4\n",
       "16        6.2\n",
       "17        7.4\n",
       "18       32.0\n",
       "19       27.0\n",
       "20        9.9\n",
       "21       13.0\n",
       "22       80.0\n",
       "23       12.0\n",
       "24       18.0\n",
       "25       13.0\n",
       "26        7.7\n",
       "27       44.0\n",
       "28       11.0\n",
       "29       11.0\n",
       "30       20.0\n",
       "31       14.0\n",
       "32       26.0\n",
       "33       18.0\n",
       "         ... \n",
       "72539    51.0\n",
       "72540     7.9\n",
       "72541    12.0\n",
       "72543    94.0\n",
       "72545    86.0\n",
       "72546    11.0\n",
       "72547    72.0\n",
       "72548     8.8\n",
       "72549    14.0\n",
       "72551    99.0\n",
       "72553     8.2\n",
       "72554    18.0\n",
       "72555    99.0\n",
       "72556    17.0\n",
       "72557     1.6\n",
       "72558    23.0\n",
       "72559    99.0\n",
       "72560    99.0\n",
       "72561    42.0\n",
       "72562    29.0\n",
       "72563    25.0\n",
       "72565    46.0\n",
       "72566     1.6\n",
       "72567    84.0\n",
       "72568    36.0\n",
       "72569    36.0\n",
       "72570     6.8\n",
       "72571    99.0\n",
       "72572    99.0\n",
       "72573    99.0\n",
       "Name: win_odds, Length: 65626, dtype: float64"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keras_3['win_odds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1197\n"
     ]
    }
   ],
   "source": [
    "temp = len(races)\n",
    "print(temp)\n",
    "# hit = 0\n",
    "balance = [0]\n",
    "\n",
    "for race in races:\n",
    "    \n",
    "    trial = df_rf_walk[df_rf_walk['race_id'] == race]\n",
    "    \n",
    "    if len(trial) < trial['horse_count'].max():\n",
    "        \n",
    "        continue\n",
    "        \n",
    "    Y_trial = trial['finish_time'].values\n",
    "    X_trial = trial.drop(['finish_time', 'race_id'], axis=1)\n",
    "    y_pred = forest.predict(X_trial)\n",
    "    \n",
    "    results = pd.DataFrame(y_pred, columns=['predicted_finishing_time'])\n",
    "    results = pd.concat([results, pd.DataFrame(Y_trial, columns=['actual_finishing_time'])], axis=1)\n",
    "    results = results = pd.concat([results, trial['win_odds'].reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    results = results.sort_values(by='predicted_finishing_time').reset_index(drop=True).reset_index()\n",
    "    results.columns=['predicted_rank', 'predicted_finishing_time', 'actual_finishing_time', 'win_odds']\n",
    "    results = results.sort_values(by='actual_finishing_time').reset_index(drop=True).reset_index()\n",
    "    results.columns=['actual_rank', 'predicted_rank', 'predicted_finishing_time', 'actual_finishing_time', 'win_odds']\n",
    "    \n",
    "    odds = results[(results['predicted_rank'] == 0)]['win_odds'].values[0]\n",
    "    \n",
    "    if odds < 5:\n",
    "        \n",
    "        balance.append(balance[-1])\n",
    "    \n",
    "    elif len(results[(results['predicted_rank'] == 0) & (results['actual_rank'] == 0)]) == 1:\n",
    "            \n",
    "        balance.append(balance[-1] + 10 * odds)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        balance.append(balance[-1] - 10)\n",
    "    \n",
    "# print(hit, '/', (temp * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " -10,\n",
       " -10,\n",
       " -20,\n",
       " -30,\n",
       " -30,\n",
       " -30,\n",
       " -30,\n",
       " -40,\n",
       " -50,\n",
       " -60,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 8.0,\n",
       " -2.0,\n",
       " -2.0,\n",
       " 53.0,\n",
       " 43.0,\n",
       " 33.0,\n",
       " 23.0,\n",
       " 23.0,\n",
       " 23.0,\n",
       " 13.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " -7.0,\n",
       " -17.0,\n",
       " -17.0,\n",
       " -17.0,\n",
       " 48.0,\n",
       " 48.0,\n",
       " 48.0,\n",
       " 48.0,\n",
       " 48.0,\n",
       " 48.0,\n",
       " 130.0,\n",
       " 130.0,\n",
       " 130.0,\n",
       " 130.0,\n",
       " 130.0,\n",
       " 120.0,\n",
       " 120.0,\n",
       " 120.0,\n",
       " 182.0,\n",
       " 272.0,\n",
       " 262.0,\n",
       " 329.0,\n",
       " 329.0,\n",
       " 329.0,\n",
       " 428.0,\n",
       " 484.0,\n",
       " 624.0,\n",
       " 699.0,\n",
       " 699.0,\n",
       " 699.0,\n",
       " 699.0,\n",
       " 689.0,\n",
       " 689.0,\n",
       " 770.0,\n",
       " 760.0,\n",
       " 834.0,\n",
       " 834.0,\n",
       " 834.0,\n",
       " 834.0,\n",
       " 824.0,\n",
       " 824.0,\n",
       " 824.0,\n",
       " 886.0,\n",
       " 886.0,\n",
       " 886.0,\n",
       " 938.0,\n",
       " 938.0,\n",
       " 938.0,\n",
       " 928.0,\n",
       " 918.0,\n",
       " 908.0,\n",
       " 898.0,\n",
       " 898.0,\n",
       " 898.0,\n",
       " 898.0,\n",
       " 888.0,\n",
       " 1028.0,\n",
       " 1018.0,\n",
       " 1094.0,\n",
       " 1094.0,\n",
       " 1084.0,\n",
       " 1084.0,\n",
       " 1074.0,\n",
       " 1064.0,\n",
       " 1064.0,\n",
       " 1064.0,\n",
       " 1054.0,\n",
       " 1054.0,\n",
       " 1044.0,\n",
       " 1044.0,\n",
       " 1044.0,\n",
       " 1034.0,\n",
       " 1034.0,\n",
       " 1024.0,\n",
       " 1024.0,\n",
       " 1024.0,\n",
       " 1024.0,\n",
       " 1014.0,\n",
       " 1014.0,\n",
       " 1014.0,\n",
       " 1069.0,\n",
       " 1059.0,\n",
       " 1136.0,\n",
       " 1136.0,\n",
       " 1136.0,\n",
       " 1136.0,\n",
       " 1136.0,\n",
       " 1136.0,\n",
       " 1136.0,\n",
       " 1136.0,\n",
       " 1126.0,\n",
       " 1126.0,\n",
       " 1116.0,\n",
       " 1106.0,\n",
       " 1106.0,\n",
       " 1106.0,\n",
       " 1096.0,\n",
       " 1086.0,\n",
       " 1076.0,\n",
       " 1076.0,\n",
       " 1076.0,\n",
       " 1076.0,\n",
       " 1066.0,\n",
       " 1066.0,\n",
       " 1066.0,\n",
       " 1056.0,\n",
       " 1056.0,\n",
       " 1056.0,\n",
       " 1056.0,\n",
       " 1056.0,\n",
       " 1046.0,\n",
       " 1104.0,\n",
       " 1104.0,\n",
       " 1104.0,\n",
       " 1094.0,\n",
       " 1094.0,\n",
       " 1148.0,\n",
       " 1148.0,\n",
       " 1138.0,\n",
       " 1128.0,\n",
       " 1118.0,\n",
       " 1108.0,\n",
       " 1108.0,\n",
       " 1108.0,\n",
       " 1108.0,\n",
       " 1108.0,\n",
       " 1164.0,\n",
       " 1154.0,\n",
       " 1226.0,\n",
       " 1216.0,\n",
       " 1216.0,\n",
       " 1206.0,\n",
       " 1206.0,\n",
       " 1196.0,\n",
       " 1196.0,\n",
       " 1196.0,\n",
       " 1196.0,\n",
       " 1256.0,\n",
       " 1426.0,\n",
       " 1426.0,\n",
       " 1477.0,\n",
       " 1467.0,\n",
       " 1467.0,\n",
       " 1467.0,\n",
       " 1457.0,\n",
       " 1524.0,\n",
       " 1514.0,\n",
       " 1514.0,\n",
       " 1514.0,\n",
       " 1514.0,\n",
       " 1565.0,\n",
       " 1555.0,\n",
       " 1545.0,\n",
       " 1535.0,\n",
       " 1525.0,\n",
       " 1515.0,\n",
       " 1505.0,\n",
       " 1505.0,\n",
       " 1557.0,\n",
       " 1547.0,\n",
       " 1547.0,\n",
       " 1547.0,\n",
       " 1547.0,\n",
       " 1547.0,\n",
       " 1547.0,\n",
       " 1537.0,\n",
       " 1527.0,\n",
       " 1517.0,\n",
       " 1517.0,\n",
       " 1517.0,\n",
       " 1517.0,\n",
       " 1507.0,\n",
       " 1559.0,\n",
       " 1549.0,\n",
       " 1539.0,\n",
       " 1539.0,\n",
       " 1539.0,\n",
       " 1539.0,\n",
       " 1600.0,\n",
       " 1590.0,\n",
       " 1648.0,\n",
       " 1648.0,\n",
       " 1638.0,\n",
       " 1628.0,\n",
       " 1628.0,\n",
       " 1628.0,\n",
       " 1685.0,\n",
       " 1675.0,\n",
       " 1675.0,\n",
       " 1675.0,\n",
       " 1675.0,\n",
       " 1675.0,\n",
       " 1675.0,\n",
       " 1675.0,\n",
       " 1665.0,\n",
       " 1665.0,\n",
       " 1665.0,\n",
       " 1665.0,\n",
       " 1665.0,\n",
       " 1665.0,\n",
       " 1665.0,\n",
       " 1665.0,\n",
       " 1665.0,\n",
       " 1655.0,\n",
       " 1765.0,\n",
       " 1765.0,\n",
       " 1755.0,\n",
       " 1745.0,\n",
       " 1745.0,\n",
       " 1745.0,\n",
       " 1735.0,\n",
       " 1725.0,\n",
       " 1784.0,\n",
       " 1784.0,\n",
       " 1784.0,\n",
       " 1774.0,\n",
       " 1764.0,\n",
       " 1764.0,\n",
       " 1764.0,\n",
       " 1764.0,\n",
       " 1764.0,\n",
       " 1754.0,\n",
       " 1754.0,\n",
       " 1845.0,\n",
       " 1933.0,\n",
       " 1933.0,\n",
       " 1923.0,\n",
       " 2053.0,\n",
       " 2043.0,\n",
       " 2043.0,\n",
       " 2033.0,\n",
       " 2102.0,\n",
       " 2102.0,\n",
       " 2102.0,\n",
       " 2102.0,\n",
       " 2102.0,\n",
       " 2102.0,\n",
       " 2092.0,\n",
       " 2092.0,\n",
       " 2092.0,\n",
       " 2092.0,\n",
       " 2092.0,\n",
       " 2082.0,\n",
       " 2072.0,\n",
       " 2072.0,\n",
       " 2072.0,\n",
       " 2062.0,\n",
       " 2052.0,\n",
       " 2042.0,\n",
       " 2032.0,\n",
       " 2022.0,\n",
       " 2106.0,\n",
       " 2106.0,\n",
       " 2096.0,\n",
       " 2096.0,\n",
       " 2096.0,\n",
       " 2096.0,\n",
       " 2206.0,\n",
       " 2346.0,\n",
       " 2346.0,\n",
       " 2336.0,\n",
       " 2336.0,\n",
       " 2336.0,\n",
       " 2336.0,\n",
       " 2336.0,\n",
       " 2336.0,\n",
       " 2336.0,\n",
       " 2336.0,\n",
       " 2336.0,\n",
       " 2336.0,\n",
       " 2336.0,\n",
       " 2336.0,\n",
       " 2336.0,\n",
       " 2336.0,\n",
       " 2336.0,\n",
       " 2336.0,\n",
       " 2336.0,\n",
       " 2326.0,\n",
       " 2379.0,\n",
       " 2369.0,\n",
       " 2369.0,\n",
       " 2359.0,\n",
       " 2359.0,\n",
       " 2349.0,\n",
       " 2349.0,\n",
       " 2339.0,\n",
       " 2329.0,\n",
       " 2329.0,\n",
       " 2319.0,\n",
       " 2319.0,\n",
       " 2319.0,\n",
       " 2319.0,\n",
       " 2319.0,\n",
       " 2319.0,\n",
       " 2319.0,\n",
       " 2372.0,\n",
       " 2372.0,\n",
       " 2362.0,\n",
       " 2352.0,\n",
       " 2352.0,\n",
       " 2352.0,\n",
       " 2352.0,\n",
       " 2352.0,\n",
       " 2352.0,\n",
       " 2352.0,\n",
       " 2352.0,\n",
       " 2352.0,\n",
       " 2342.0,\n",
       " 2332.0,\n",
       " 2322.0,\n",
       " 2312.0,\n",
       " 2302.0,\n",
       " 2302.0,\n",
       " 2302.0,\n",
       " 2302.0,\n",
       " 2302.0,\n",
       " 2302.0,\n",
       " 2292.0,\n",
       " 2292.0,\n",
       " 2282.0,\n",
       " 2282.0,\n",
       " 2272.0,\n",
       " 2272.0,\n",
       " 2262.0,\n",
       " 2252.0,\n",
       " 2242.0,\n",
       " 2295.0,\n",
       " 2295.0,\n",
       " 2285.0,\n",
       " 2285.0,\n",
       " 2285.0,\n",
       " 2367.0,\n",
       " 2367.0,\n",
       " 2467.0,\n",
       " 2467.0,\n",
       " 2467.0,\n",
       " 2467.0,\n",
       " 2457.0,\n",
       " 2521.0,\n",
       " 2511.0,\n",
       " 2501.0,\n",
       " 2491.0,\n",
       " 2491.0,\n",
       " 2491.0,\n",
       " 2491.0,\n",
       " 2481.0,\n",
       " 2542.0,\n",
       " 2542.0,\n",
       " 2542.0,\n",
       " 2621.0,\n",
       " 2621.0,\n",
       " 2611.0,\n",
       " 2731.0,\n",
       " 2721.0,\n",
       " 2721.0,\n",
       " 2721.0,\n",
       " 2721.0,\n",
       " 2711.0,\n",
       " 2767.0,\n",
       " 2757.0,\n",
       " 2818.0,\n",
       " 2808.0,\n",
       " 2908.0,\n",
       " 2898.0,\n",
       " 2954.0,\n",
       " 2944.0,\n",
       " 2934.0,\n",
       " 2924.0,\n",
       " 2985.0,\n",
       " 3041.0,\n",
       " 3041.0,\n",
       " 3031.0,\n",
       " 3031.0,\n",
       " 3031.0,\n",
       " 3021.0,\n",
       " 3011.0,\n",
       " 3111.0,\n",
       " 3211.0,\n",
       " 3201.0,\n",
       " 3201.0,\n",
       " 3201.0,\n",
       " 3201.0,\n",
       " 3311.0,\n",
       " 3301.0,\n",
       " 3301.0,\n",
       " 3386.0,\n",
       " 3506.0,\n",
       " 3506.0,\n",
       " 3506.0,\n",
       " 3506.0,\n",
       " 3496.0,\n",
       " 3486.0,\n",
       " 3486.0,\n",
       " 3486.0,\n",
       " 3486.0,\n",
       " 3486.0,\n",
       " 3541.0,\n",
       " 3541.0,\n",
       " 3541.0,\n",
       " 3541.0,\n",
       " 3603.0,\n",
       " 3593.0,\n",
       " 3593.0,\n",
       " 3593.0,\n",
       " 3583.0,\n",
       " 3573.0,\n",
       " 3573.0,\n",
       " 3573.0,\n",
       " 3563.0,\n",
       " 3563.0,\n",
       " 3563.0,\n",
       " 3553.0,\n",
       " 3553.0,\n",
       " 3553.0,\n",
       " 3543.0,\n",
       " 3593.0,\n",
       " 3680.0,\n",
       " 3680.0,\n",
       " 3670.0,\n",
       " 3670.0,\n",
       " 3670.0,\n",
       " 3660.0,\n",
       " 3660.0,\n",
       " 3660.0,\n",
       " 3660.0,\n",
       " 3660.0,\n",
       " 3650.0,\n",
       " 3640.0,\n",
       " 3640.0,\n",
       " 3760.0,\n",
       " 3750.0,\n",
       " 3750.0,\n",
       " 3740.0,\n",
       " 3740.0,\n",
       " 3730.0,\n",
       " 3730.0,\n",
       " 3720.0,\n",
       " 3720.0,\n",
       " 3720.0,\n",
       " 3786.0,\n",
       " 3776.0,\n",
       " 3776.0,\n",
       " 3836.0]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2318c74f278>]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
